{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PytorchModulePCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "pip install git+https://github.com/FrancescoSaverioZuppichini/PytorchModulePCA.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "First we need to load `PytorchModulePCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PytorchModulePCA import PytorchModulePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need some data to work with, let's use the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Resize, Grayscale, RandomHorizontalFlip, RandomVerticalFlip, Normalize\n",
    "\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from fastai.vision import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_tr = Compose([RandomHorizontalFlip(), RandomVerticalFlip(), ToTensor(), Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "tr = Compose([ToTensor(), Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "train_ds = CIFAR10(root='~/Documents/datasets/', download=True, transform=train_tr)\n",
    "train_dl = DataLoader(train_ds, num_workers=14, batch_size=128, shuffle=True)\n",
    "\n",
    "val_ds = CIFAR10(root='~/Documents/datasets/',  download=True, train=False, transform=tr)\n",
    "val_dl = DataLoader(val_ds, num_workers=14, batch_size=128, shuffle=False)\n",
    "\n",
    "data = ImageDataBunch(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, we need a model to visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Let's use resnet18 \n",
    "\n",
    "![alt](https://hackernoon.com/hn-images/1*uJ0IrP9JXYE2hHAzMjorQA.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PytorchModulePCA.utils import device \n",
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18(False).to(device())\n",
    "\n",
    "last_conv_layer = model.layer4[-1].conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not trained\n",
    "\n",
    "This is how PCA in the last conv layer looks like on a untrained model. We need to unnormalize the images to properly visualise them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:model[0][2]\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "    \n",
    "un_normalize = UnNormalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "module_pca = PytorchModulePCA(model.eval(), last_conv_layer.eval(), data.valid_dl)\n",
    "module_pca(k=2, n_batches=None)\n",
    "module_pca = module_pca.reduce(to=200)\n",
    "module_pca.plot()\n",
    "plt.savefig(\"./images/7.png\") \n",
    "module_pca.annotate(zoom=0.6, transform=un_normalize)\n",
    "plt.savefig(\"./images/8.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "A quick random train. We are going to use fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(True)\n",
    "\n",
    "learn = Learner(data, model, path='./', loss_func=CrossEntropyFlat())\n",
    "learn.metrics=[accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    learn.fit(10, lr=1e-03)\n",
    "    learn.fit(5, lr=1e-04)\n",
    "    learn.save('learn', return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.load('./learn')\n",
    "last_conv_layer = learn.model.layer4[-1].conv2\n",
    "learn.validate(metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute PCA on the last conv layer\n",
    "`PytorchModulePCA` will run PCA on each batch and it stores only the points, the labels and the indeces of the dataset in RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer = learn.model.layer4[-1].conv2\n",
    "module_pca = PytorchModulePCA(learn.model.eval(), last_conv_layer.eval(), data.valid_dl)\n",
    "module_pca(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "module_pca.plot()\n",
    "plt.savefig(\"./images/0.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, it is a mess! We have too many points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce\n",
    "We can reduce the number of points by calling `.reduce`. By default it uses **kmeans** to properly select the new points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "module_pca = module_pca.reduce(to=200)\n",
    "module_pca.plot()\n",
    "plt.savefig(\"./images/1.png\") \n",
    "module_pca.annotate(zoom=0.6, transform=un_normalize)\n",
    "plt.savefig(\"./images/2.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "module_pca3d = PytorchModulePCA(learn.model, last_conv_layer, learn.data.valid_dl)\n",
    "module_pca3d(k=3)\n",
    "module_pca3d.plot()\n",
    "plt.savefig(\"./images/3.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reduced_module_pca3d = module_pca3d.reduce(to=200)\n",
    "reduced_module_pca3d.plot()\n",
    "plt.savefig(\"./images/4.png\") \n",
    "reduced_module_pca3d.annotate(zoom=0.6, transform=un_normalize)\n",
    "plt.savefig(\"./images/5.png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
